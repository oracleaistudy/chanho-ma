1. 지도 학습 알고리즘
1) 분류: 샘플을 몇 개의 클래스 중 하나로 분류

2) 회귀(regression): 두 변수 사이의 상관관계를 분석
				>> 임의의 어떤 숫자를 예측

3) k-최근접 이웃 분류 알고리즘: 예측하려는 샘플의 이웃 n개를 선택하고
			이웃의 클래스 비율을 따라가 예측

4) k-최근점 이웃 회귀: 예측하려는 샘플의 이웃 n개를 선택하고
			이웃의 타겟의 평균으로 예측

5) 정확도 vs 결정계수(coefficient of determination, R2):
	정확도: 분류에서 테스트 세트에 있는 샘플을 정확하게 분류한 개수의 비율
	결정계수: 예측한 값의 타겟과 가까운 정도
		R2 = 1 - sum(타겟 - 예측)2 / sum(타겟 - 평균)2
	* 과대적합(overfitting): 훈련 세트의 점수는 높지만 테스트 세트의 점수가 낮은 경우
		>> 훈련 모델을 단순하게 만들어 해소(이웃의 개수(k)를 늘림)
	* 과소적합(underfitting): 훈련 세트의 점수가 낮은 경우
				훈련 세트와 테스트 세트의 크기가 작은 경우 발생 가능
		>> 훈련 모델을 복잡하게 만들어 해소(이웃의 개수(k)를 줄임)
			* 이웃의 개수를 줄임: 훈련 세트의 국지적 패턴에 민감
			* 이웃의 개수를 늘림: 데이터 전반의 일반적 패턴에 따름
		>> 훈련, 테스트 세트의 크기를 키워 해소
	절댓값 오차(AE, absolute error):
		예측값과 실제값의 차이의 절댓값
		AE = |실제값 - 모델예측값|
	평균 절댓값 오차(MAE, mean absolute error):
		여러 개의 샘플을 예측한 경우 평균값
		MAE = sum(각 절댓값 오차) / n
		* 큰 오차에 덜 민감함(MSE 비교적)
	평균 제곱 오차(MSE, mean squared error):
		오차를 제곱해서 평균
		MSE = sum((각 절댓값 오차)2) / n
		* 특이값을 찾아내는데 용이
			>> 정확한 모델 유도 가능
		* 미분을 통한 최적화에 유리
	평균 제곱근 오차(RMSE, root mean squaredd error):
		MSE의 제곱근
		* 단위가 실제 데이터와 같아짐
			>> 해석이 쉬우며 큰 오차 민감함은 그대로
	>> 이상치가 거의 없는 데이터 >> RMSE
	>> 이상치가 많은 데이터 >> MAE
	>> 모델이 큰 오차를 절대 내면 안되는 경우 >> RMSE
	>> 모델 최적화가 필요한 경우 >> MSE


2. 회귀(regression)
1) 선형 회귀(linear regression)
특성이 하나인 경우 그 직선을 학습하는 알고리즘
	* 모델 파라미터(model parameter):
			머신러닝 알고리즘이 찾은 값
	* 회귀 파라미터(regression parameter):
			coef_ & intercept_의 값
	* 모델 기반 학습: 최적의 모델 파라미터를 찾는 것
				>> 머신러닝 알고리즘의 훈련 과정
	* 사례 기반 학습: 모델 파라미터없이 훈련 세트를 저장하여 훈련하는 것

2) 다항 회귀(polynomial regression)
다항식을 사용한 선형 회귀
	* 선형 회귀는 가중치와 타겟 사이의 관계를 찾는 것으로 다항식도 모두 선형 회귀


3. 특성 공학과 규제
1) 다중 회귀(multiple regression):
여러 개의 특성을 사용한 선형 회귀 알고리즘

2) 특성 공학(feature engineering):
기존의 특성을 사용해 새로운 특성을 뽑아내는 작업

3) 규제(regularization)
머신러닝 모델이 훈련 세트에 과대적합되지 않도록 억제
	>> 선형 회귀의 경우 특성의 계수를 작게
 (1) 릿지(ridge): 규제한 선형 회귀 모델, 계수를 제곱한 값을 기준으로 규제를 적용

 (2) 라쏘(lasso): 규제한 선형 회귀 모델, 계수의 절댓값을 기준으로 규제를 적용
	라쏘 모델은 계수를 0으로 만들 수 있음
		>> 유용한 특성만 골라서 모델을 구축
		>> print(np.sum(lasso.coef_ == 0))

* 추정기(estimator) vs 변환기(transformer)
추정기: 파라미터를 추정해서 예측하는 역할
	fit(), predict()를 가지고 있음
변환기: 입력 데이터를 변환하는 역할
	fit(), transform()를 가지고 있음