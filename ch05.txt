1. 결정트리(decision tree):
 질문을 통해 정답을 맞춰가는 모델
 1) 노드(node):
	결정 트리를 구성하는 요소
	하나의 노드는 2개의 가지를 가지며 true, false로 진행
 - 루트 노드(root node): 상위 노드
 - 리프 노드(leaf node): 하위 노드

2) 지니(gini):
	지니 불순도(gini impurity)
	DecisionTreeClassifier 클래스의 criterion 매개변수 기본값
	>> gini impurity = 1 - (음성 클래스 비율2 + 양성 클래스 비율2)
		* 음성 클래스: value의 우측 값
		  양성 클래스: value의 좌측 값

3) 정보이득(information gain):
	부모 자식 노드 사이의 불순도 차이
	부모 불순도 - (양성클래스 / 부모 샘플 수) * 양성클래스 불순도 - (음성클래스 / 부모 샘플 수) * 음성클래스 불순도
	정보이득이 최대가 되도록 노드를 분할

4) 엔트로피 불순도(entropy impurity):
	- 음성 클래스 비율 * log2(음성 클래스 비율) - 양성 클래스 비율 * log2(양성 클래스 비율)


2. 교차 검증과 그리드 서치
1) 검증 세트(validation set, 개발 세트, dev set): 과(소)적합 판별을 위한 추가 확인 세트
 (1) 교차 검증(cross validation):
	훈련 세트를 여러 부분을 나누어 반복하며 검증 세트로 평가하는 과정
	ex) 3-폴드 교차 검증(k-fold cross validation):
		훈련 세트를 3개로 나누어 교차 검증을 수행

2) 그리드 서치(grid search):
	하이퍼 파라미터 튜닝
	* 하이퍼 파라미터: 모델이 학습할 수 없어 사용자가 지정해야하는 파라미터

3) 랜덤 서치(random search):
	하이퍼 파라미터를 샘플링할 수 있는 확률 분포에 따라 튜닝


3. 트리의 앙상블
1) 랜덤 포레스트(random forest): 앙상블 학습의 일종, 여러 결정 트리를 만들어 각 결과를 종합하여 최종 예측을 생성
	>> 부트스트랩 샘플(bootstrap sample): 결정 트리에서 복원 추출을 통해 나온 샘플들

2) 정형 데이터 vs 비정형 데이터
 (1) 정형 데이터(structured data): 숫자, 단어 등 정리된 정보
 (2) 비정형 데이터(unstructured data): 그림, 말 등 정리되지 않은 정보

3) 앙상블 학습(enxemble learning): 정형 데이터 처리 알고리즘(결정트리 기반)

4) 엑스트라 트리(Extra Trees): 결정 트리를 만들 때 전체 훈련 세트를 사용하여 결과 생성

5) 그레이디언트 부스팅(gradient boosting): 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블

6) 히스토그램 기반 그레이디언트 부스팅(histogram-based gradient boosting):
	